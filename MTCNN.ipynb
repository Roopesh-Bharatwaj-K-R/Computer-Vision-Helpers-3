{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c311515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eeedec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242d2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "716a4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector =MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1348ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input_path INPUT_PATH]\n",
      "                             [--input_type INPUT_TYPE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/roopesh/.local/share/jupyter/runtime/kernel-604f8cb6-eb07-4d33-8fc8-58b03adb089b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input_path', default='sample/2.jpg', help=\"it can be image or video or webcan id\")\n",
    "parser.add_argument('--input_type', default='image', help= \"either image or video (for video file and webcam id)\")\n",
    "opt = parser.parse_args()\n",
    "\n",
    "# define HSV color ranges for eyes colors\n",
    "class_name = (\"Blue\", \"Blue Gray\", \"Brown\", \"Brown Gray\", \"Brown Black\", \"Green\", \"Green Gray\", \"Other\")\n",
    "EyeColor = {\n",
    "    class_name[0] : ((166, 21, 50), (240, 100, 85)),\n",
    "    class_name[1] : ((166, 2, 25), (300, 20, 75)),\n",
    "    class_name[2] : ((2, 20, 20), (40, 100, 60)),\n",
    "    class_name[3] : ((20, 3, 30), (65, 60, 60)),\n",
    "    class_name[4] : ((0, 10, 5), (40, 40, 25)),\n",
    "    class_name[5] : ((60, 21, 50), (165, 100, 85)),\n",
    "    class_name[6] : ((60, 2, 25), (165, 20, 65))\n",
    "}\n",
    "\n",
    "def check_color(hsv, color):\n",
    "    if (hsv[0] >= color[0][0]) and (hsv[0] <= color[1][0]) and (hsv[1] >= color[0][1]) and \\\n",
    "    hsv[1] <= color[1][1] and (hsv[2] >= color[0][2]) and (hsv[2] <= color[1][2]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# define eye color category rules in HSV space\n",
    "def find_class(hsv):\n",
    "    color_id = 7\n",
    "    for i in range(len(class_name)-1):\n",
    "        if check_color(hsv, EyeColor[class_name[i]]) == True:\n",
    "            color_id = i\n",
    "\n",
    "    return color_id\n",
    "\n",
    "def eye_color(image):\n",
    "    imgHSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    h, w = image.shape[0:2]\n",
    "    imgMask = np.zeros((image.shape[0], image.shape[1], 1))\n",
    "    \n",
    "    result = detector.detect_faces(image)\n",
    "    if result == []:\n",
    "        print('Warning: Can not detect any face in the input image!')\n",
    "        return\n",
    "\n",
    "    bounding_box = result[0]['box']\n",
    "    left_eye = result[0]['keypoints']['left_eye']\n",
    "    right_eye = result[0]['keypoints']['right_eye']\n",
    "\n",
    "    eye_distance = np.linalg.norm(np.array(left_eye)-np.array(right_eye))\n",
    "    eye_radius = eye_distance/15 # approximate\n",
    "   \n",
    "    cv2.circle(imgMask, left_eye, int(eye_radius), (255,255,255), -1)\n",
    "    cv2.circle(imgMask, right_eye, int(eye_radius), (255,255,255), -1)\n",
    "\n",
    "    cv2.rectangle(image,\n",
    "              (bounding_box[0], bounding_box[1]),\n",
    "              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "              (255,155,255),\n",
    "              2)\n",
    "\n",
    "    cv2.circle(image, left_eye, int(eye_radius), (0, 155, 255), 1)\n",
    "    cv2.circle(image, right_eye, int(eye_radius), (0, 155, 255), 1)\n",
    "\n",
    "    eye_class = np.zeros(len(class_name), np.float)\n",
    "\n",
    "    for y in range(0, h):\n",
    "        for x in range(0, w):\n",
    "            if imgMask[y, x] != 0:\n",
    "                eye_class[find_class(imgHSV[y,x])] +=1 \n",
    "\n",
    "    main_color_index = np.argmax(eye_class[:len(eye_class)-1])\n",
    "    total_vote = eye_class.sum()\n",
    "\n",
    "    print(\"\\n\\nDominant Eye Color: \", class_name[main_color_index])\n",
    "    print(\"\\n **Eyes Color Percentage **\")\n",
    "    for i in range(len(class_name)):\n",
    "        print(class_name[i], \": \", round(eye_class[i]/total_vote*100, 2), \"%\")\n",
    "    \n",
    "    label = 'Dominant Eye Color: %s' % class_name[main_color_index]  \n",
    "    cv2.putText(image, label, (left_eye[0]-10, left_eye[1]-40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (155,255,0))\n",
    "    cv2.imshow('EYE-COLOR-DETECTION', image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "#     # image \n",
    "#     if opt.input_type == '//home/roopesh/Desktop/images/image3.png':   \n",
    "#         image = cv2.imread(opt.input_path, cv2.IMREAD_COLOR)\n",
    "#         # detect color percentage\n",
    "#         eye_color(image)\n",
    "#         cv2.imwrite('/home/roopesh/Desktop/result.jpg', image)    \n",
    "#         cv2.waitKey(0)\n",
    "\n",
    "    # video or webcam\n",
    "#     else: \n",
    "    cap = cv2.VideoCapture(opt.input_path)\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == -1: \n",
    "            break\n",
    "\n",
    "        eye_color(frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae3fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
